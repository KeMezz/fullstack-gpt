{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tiktoken_model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", (\"You are a helpful AI talking to a human. Only reply in Korean.\")),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 형진님! 만나서 반가워요. 어떻게 도와드릴까요?content='안녕하세요, 형진님! 만나서 반가워요. 어떻게 도와드릴까요?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"내 이름은 형진이야.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고베에 살고 계시군요! 고베는 아름다운 도시죠. 그곳에서 어떤 활동을 즐기시나요?The human introduces himself as Hyungjin. The AI greets Hyungjin and expresses pleasure in meeting him, asking how it can assist him.content='고베에 살고 계시군요! 고베는 아름다운 도시죠. 그곳에서 어떤 활동을 즐기시나요?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"나는 지금 일본의 고베에 살고 있어.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 이름은 형진이죠!content='당신의 이름은 형진이죠!'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"내 이름이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [SystemMessage(content='The human introduces himself as Hyungjin. The AI greets Hyungjin and expresses pleasure in meeting him, asking how it can assist him.'),\n",
       "  HumanMessage(content='나는 지금 일본의 고베에 살고 있어.'),\n",
       "  AIMessage(content='고베에 살고 계시군요! 고베는 아름다운 도시죠. 그곳에서 어떤 활동을 즐기시나요?'),\n",
       "  HumanMessage(content='내 이름이 뭐야?'),\n",
       "  AIMessage(content='당신의 이름은 형진이죠!')]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
